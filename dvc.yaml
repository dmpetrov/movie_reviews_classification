stages:
  get_data:
    cmd: make download_data
    outs:
    - data/raw/labeledTrainData.tsv:
        cache: false
    - data/raw/testData.tsv:
        cache: false
    - data/raw/unlabeledTrainData.tsv:
        cache: false
  split:
    cmd: python movie_reviews_classification/data/train_valid_split.py data/raw/labeledTrainData.tsv
      data/interim --column sentiment
    deps:
    - data/raw/labeledTrainData.tsv
    - movie_reviews_classification/data/train_valid_split.py
    params:
    - data.test_size
    outs:
    - data/interim/labeledTrainData.train.csv:
        cache: false
    - data/interim/labeledTrainData.valid.csv:
        cache: false
  train:
    cmd: nohup python -m deeppavlov train models/conversation_bert.json -d > data/logs/conversation_bert.log;
      tail -n 2 data/logs/conversation_bert.log | head -n 1 > /tmp/train_log.json;
      tail -n 1 data/logs/conversation_bert.log > /tmp/valid_log.json;
      jq -s '.[0] * .[1]' /tmp/train_log.json /tmp/valid_log.json > data/summary/conversation_bert.json
    deps:
    - data/interim/labeledTrainData.train.csv
    - data/interim/labeledTrainData.valid.csv
    - models/conversation_bert.json
    outs:
    - models_data/classifiers/movie_reviews_conv_bert:
        cache: false
    - data/logs/conversation_bert.log:
        cache: false
    metrics:
    - data/summary/conversation_bert.json:
        cache: false